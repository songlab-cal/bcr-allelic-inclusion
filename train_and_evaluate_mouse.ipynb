{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8618fe1a-cf5b-4b98-bb0e-a1d793c6f734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tqdm.pandas()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.getcwd() + '/src')\n",
    "from cnn import CNN\n",
    "from utils import embed_genes, embed_seqs, ALPHABET\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "EPOCHS = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_DIR = os.getcwd() + '/data/'\n",
    "MODEL_DIR = os.getcwd() + '/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e2a29f-a42a-4de9-8fa9-2122b3c8a84d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, device, train_tuple, test_tuple, optimizer, criterion, epoch, batch_size=10000):\n",
    "    model.train()\n",
    "    x,v,j,y = train_tuple\n",
    "    xt,vt,jt,yt = test_tuple\n",
    "\n",
    "    train_loss = []\n",
    "\n",
    "    for i in range(0, x.shape[0], batch_size):\n",
    "        x_i = x[i:i+batch_size]\n",
    "        v_i = v[i:i+batch_size]\n",
    "        j_i = j[i:i+batch_size]\n",
    "        y_i = y[i:i+batch_size]\n",
    "        x_i, v_i, j_i, y_i = x_i.to(device), v_i.to(device), j_i.to(device), y_i.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_i, v_i, j_i)\n",
    "        loss = criterion(output, y_i)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        x_i, v_i, j_i, y_i = x_i.cpu(), v_i.cpu(), j_i.cpu(), y_i.cpu()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    train_loss = np.array(train_loss).mean()\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = criterion(model(xt, vt, jt), yt).detach().cpu().numpy()\n",
    "    print('Epoch [{}], Train loss: {}, Test loss: {}'.format(epoch, train_loss, test_loss), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b8eb8-b339-4adc-bcf6-ffea765c6d17",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077f7b58-20d5-4c2f-9675-613986f123da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21675696/21675696 [00:32<00:00, 662007.74it/s]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_DIR + 'mouse/C57BL6_mouse_1234_merged_reduced.csv.gz', compression='gzip')[\n",
    "    ['aaSeqCDR3', 'bestVHit', 'bestDHit', 'bestJHit', 'source', 'individual']]\n",
    "in_alph = data.aaSeqCDR3.progress_apply(lambda x: len(set(x) - set(ALPHABET)) == 0)\n",
    "data = data[in_alph]\n",
    "conserved_C = (data.aaSeqCDR3.str[0] == 'C')\n",
    "data = data[conserved_C]\n",
    "conserved_W = (data.aaSeqCDR3.str[-1] == 'W')\n",
    "data = data[conserved_W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87762e9c-4796-41f0-b21a-e8cccbf23c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20805480/20805480 [00:15<00:00, 1328361.00it/s]\n"
     ]
    }
   ],
   "source": [
    "data['length'] = data.aaSeqCDR3.progress_apply(lambda x: len(x))\n",
    "data = data[data.length <= 32]\n",
    "data = data[data.length >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5278b8fd-2fa6-4ae1-a5d3-d9c59ffa22c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_v = 90\n",
    "\n",
    "J_GENES = data.bestJHit.value_counts()[:4].index.tolist()\n",
    "J_GENES = {J_GENES[i]:i for i in range(len(J_GENES))}\n",
    "V_GENES = data[data.source == 'naive'].bestVHit.value_counts()[:n_v].index.tolist()\n",
    "V_GENES = {V_GENES[i]:i for i in range(len(V_GENES))}\n",
    "\n",
    "data = data[data.bestVHit.isin(V_GENES)]\n",
    "data = data[data.bestJHit.isin(J_GENES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cae0ab-2e86-4290-8f27-ec343dd4f934",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15373a92-9363-4814-910c-600a0f0df287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:01<04:05, 61.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train loss: 0.8060317635536194, Test loss: 0.7596032619476318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:33<02:12, 44.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train loss: 0.7630923390388489, Test loss: 0.7555277347564697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:04<01:16, 38.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train loss: 0.7553618550300598, Test loss: 0.7487244606018066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:37<00:36, 36.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train loss: 0.7504685521125793, Test loss: 0.7467759251594543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:09<00:00, 37.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train loss: 0.7469162940979004, Test loss: 0.7514888644218445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Here we train on 3 mice and hold out the 4th\n",
    "### In the paper we report results by averaging all four possible such models\n",
    "### Here we train only one.\n",
    "### Results will differ slightly, also due to replicate variance\n",
    "\n",
    "mouse = pd.unique(data.individual)[0]\n",
    "\n",
    "train = data[data.individual != mouse]\n",
    "valid = data[data.individual == mouse]\n",
    "\n",
    "train = train.groupby('source').sample(n=int(0.7 * train.source.value_counts().min())).reset_index(drop = True)\n",
    "valid = valid.groupby('source').sample(n=10000).reset_index(drop = True)\n",
    "\n",
    "train_x = embed_seqs(train.aaSeqCDR3.to_numpy(), pad_length=32, alph=ALPHABET).float()\n",
    "train_v = embed_genes(train['bestVHit'].to_numpy(), V_GENES).float()\n",
    "train_j = embed_genes(train['bestJHit'].to_numpy(), J_GENES).float()\n",
    "train_y = torch.from_numpy(\n",
    "    (1*(train['source'] == 'preB') + 2*(train['source'] == 'naive')).to_numpy()).long()\n",
    "train_tuple = (train_x, train_v, train_j, train_y)\n",
    "\n",
    "valid_x = embed_seqs(valid.aaSeqCDR3.to_numpy(), pad_length=32, alph=ALPHABET).float().to(device)\n",
    "valid_v = embed_genes(valid['bestVHit'].to_numpy(), V_GENES).float().to(device)\n",
    "valid_j = embed_genes(valid['bestJHit'].to_numpy(), J_GENES).float().to(device)\n",
    "valid_y = torch.from_numpy(\n",
    "    (1*(valid['source'] == 'preB') + 2*(valid['source'] == 'naive')).to_numpy()).long().to(device)\n",
    "valid_tuple = (valid_x, valid_v, valid_j, valid_y)\n",
    "\n",
    "model = CNN(use_vj=False, num_v=len(V_GENES), num_j=len(J_GENES)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    shuffle = torch.randperm(train_x.size(0))\n",
    "    train_x = train_x[shuffle]\n",
    "    train_v = train_v[shuffle]\n",
    "    train_j = train_j[shuffle]\n",
    "    train_y = train_y[shuffle]\n",
    "    train_tuple = (train_x, train_v, train_j, train_y)\n",
    "    train_epoch(model, device, train_tuple, valid_tuple, optimizer, criterion, epoch)\n",
    "    torch.save(model.state_dict(), MODEL_DIR + 'mouse_cnn_{0}.pt'.format(mouse))\n",
    "\n",
    "train_x = None; train_v = None; train_j = None; train_y = None\n",
    "valid_x = None; valid_v = None; valid_j = None; valid_y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fcf0e-bc32-4330-8753-f76b3879368a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Load and score polyreactivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f949f4-6689-4322-9247-6af4d3f7d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_data = pd.read_csv(DATA_DIR + 'mouse/poly_mouse.csv')\n",
    "poly_data['length'] = poly_data.CDRH3.apply(lambda x: len(x))\n",
    "poly_data = poly_data[poly_data.length >= 7]\n",
    "poly_data = poly_data[poly_data.length <= 32]\n",
    "poly_data = poly_data[poly_data.CDRH3.apply(lambda x: len(set(x) - set(ALPHABET))) == 0]\n",
    "\n",
    "x_p = embed_seqs(poly_data.CDRH3.to_numpy(), pad_length=32, alph=ALPHABET).float().to(device)\n",
    "\n",
    "scores = model(x_p, None, None).detach().cpu()\n",
    "scores -= torch.logsumexp(scores, dim=1, keepdim=True)\n",
    "scores = scores.numpy()\n",
    "\n",
    "poly_data['cnn_igor'] = scores[:, 0]\n",
    "poly_data['cnn_pre'] = scores[:, 1]\n",
    "poly_data['cnn_naive'] = scores[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed4f38c-9196-426a-a049-9c0feb003375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=21557.0, pvalue=8.839563440718206e-06)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistically significant difference based on naive/pre log odds\n",
    "\n",
    "naive_pre_odds = poly_data.cnn_naive - poly_data.cnn_pre\n",
    "non_odds = naive_pre_odds[poly_data.poly_count <= 0]\n",
    "poly_odds = naive_pre_odds[poly_data.poly_count >= 2]\n",
    "\n",
    "mannwhitneyu(non_odds, poly_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3cf93e-c898-4d98-a7db-08ce1873241c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18340.0, pvalue=0.19026368174736452)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No significant difference based on naive/igor log odds\n",
    "\n",
    "naive_igor_odds = poly_data.cnn_naive - poly_data.cnn_igor\n",
    "non_odds = naive_igor_odds[poly_data.poly_count <= 0]\n",
    "poly_odds = naive_igor_odds[poly_data.poly_count >= 2]\n",
    "\n",
    "mannwhitneyu(non_odds, poly_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9da1388-336e-4cfe-8bc0-7cea16b7c66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=17869.0, pvalue=0.3947940029493612)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No significant difference based on pre/igor log odds\n",
    "\n",
    "pre_igor_odds = poly_data.cnn_pre - poly_data.cnn_igor\n",
    "non_odds = pre_igor_odds[poly_data.poly_count <= 0]\n",
    "poly_odds = pre_igor_odds[poly_data.poly_count >= 2]\n",
    "\n",
    "mannwhitneyu(non_odds, poly_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8d954-c24b-4114-b913-19bcb56feadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "immuno_kernel",
   "language": "python",
   "name": "immuno_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
